{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM (3) (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R02M2X1LdLBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "1c9966e0-8850-42e6-9e49-43e8ac873860"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wZrn8Utfhyn",
        "colab_type": "text"
      },
      "source": [
        "#Problem Set 2: Linear Discriminant Functions and Support Vector Machines\n",
        "\n",
        "Rhea Carmel Glen Rodrigues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCYw8BzQfb4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A5yw4dwgN4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b3a7e75-90ba-4f49-859a-0e6611fb1f45"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC7olAW5gRuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_AaXGl6gaq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6DIFg4dgie6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3002a7d0-fe4b-4d05-a1e9-18f886519dd9"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnkYYcnrgpgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc53e7f9-003c-438e-9b3e-8bffd4d209cb"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHNRgxU1gvAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_train.reshape(60000,784)\n",
        "X_test=X_test.reshape(10000,784)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-QPH9png4Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "param_C = 5\n",
        "param_gamma = 'scale'\n",
        "classifier = SVC(C=param_C,gamma=param_gamma)      # used rbf kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piJ3npHJhO_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "08b9a4e2-4add-47d6-c4d4-5d0525ec6cc1"
      },
      "source": [
        "classifier.fit(X_train,Y_train)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeoHiFXGhTP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predict=classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc-arai97Q6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBoQecAe75FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5685f55a-2955-457d-99c5-101c02bb7e23"
      },
      "source": [
        "print(\"accuracy  {}\".format(accuracy_score(Y_test,Predict)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  98.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9SHpKQH8A_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQBJU1K7CVFD",
        "colab_type": "text"
      },
      "source": [
        "#Part 2\n",
        "\n",
        "Identify the langrange dual problem of the following primal problem: where features are given as $(x_1,y_1),.....,(x_N,y_N) $ where $y_1,....,y_{N} \\epsilon$ {-1,1}.\n",
        "\n",
        "The 1 norm soft margin  is represented as \n",
        "minimize $W^{T}.W+C\\Sigma_{i}E_{i}$ where\n",
        " W is the separating vector, $W^{T}.W$ is the dot product, and $E_{i}$ is the error made by separating vector w on feature ($x_{i},y_{i})$.\n",
        "Subject to $y_{i}.(W^{T}.x_{i})>=1-E_{i}$ and  $E_{i}>=0$ \n",
        "\n",
        "\n",
        "The langrange for 1-norm soft margin is given as\n",
        "\n",
        ">>>$L= \\frac{1}{2}.W^{T}.W +C \\sum_{i=1}^{N}E_{i}+\\sum_{i=1}^{N} \\alpha_{i}(1-y_{i}W^{T}x_{i} - E_{i}) -\\sum_{i=1}^{N}\\beta_{i}E_{i}$        \\(**1**)\n",
        "\n",
        "Claim:\n",
        " \n",
        "  > > > > > max$_{\\alpha}$min$_{w}$L <= min$_{w}$max$_{\\alpha}$L\n",
        "\n",
        " where max$_{\\alpha}$min$_{w}$L is a dual solution \n",
        " and  min$_{w}$max$_{\\alpha}$L is a primal solution.\n",
        "\n",
        "\n",
        " we use dual solution as its easier to find.\n",
        "\n",
        " $\\frac{\\partial L}{\\partial w} $  = $ w- \\sum_{i}\\alpha_{i}y_{i}x_{i}$=0\n",
        "\n",
        "$w=^{+}_{-}\\sum_{i}\\alpha_{i}y_{i}x_{i}$\n",
        "\n",
        "\n",
        "Inorder to find an equation for C we can differentiate the  Langrang equation with respect to error $E_{i}$ as show below\n",
        "\n",
        "$\\frac{\\partial L}{\\partial E}= C-\\alpha_{i}-\\beta_{i}$=0\n",
        "\n",
        "$C=\\alpha_{i}+\\beta_{i}$\n",
        "\n",
        "substitue in eq 1 we get\n",
        "\n",
        "L=$\\frac{1}{2}w^{T}(\\sum_{i}^{N}\\alpha_{\n",
        "i}y_{i}x_{i})+ \\sum_{i}^{N}\\alpha_{i}-W^{T}\\sum_{i=1}^{n}y_{i}x_{i}\\alpha_{i}$\n",
        "\n",
        "=$\\sum_{i=1}^{N}\\alpha_{i}-\\frac{1}{2}W^{t}(\\sum_{i=1}^{n}y_{i}\\alpha_{i}x_{i})$\n",
        "\n",
        "=$\\sum_{i=1}^{N}\\alpha_{i}-\\frac{1}{2}\\sum_{i,j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}x_{i}x_{j}^{T}$\n",
        "\n",
        "where $W^{t}=\\alpha_{j}y_{j}x_{j}^{T}$\n",
        "\n",
        "\n",
        "Primal margin can be given as :\n",
        "\n",
        "$\\frac{1}{\\sqrt{W^{T}.W+C\\sum_{i=1}^{n}E_{i}}}$\n",
        "\n",
        "Dual margin:\n",
        "\n",
        "$\\frac{1}{\\sqrt{\\alpha_{i}\\alpha_{j}y_{i}y_{j}x_{i}x_{j}^{T}}}$\n",
        "\n",
        "\n",
        "\n",
        "##Benefits of maximizing the margin:\n",
        "A large margin effectively corresponds to a regularization of SVM weights which prevents overfitting. Moreover large margin will create more effective classification.\n",
        "\n",
        "##Characterize the support vectors\n",
        "* Support vectors lie on the margin.\n",
        "* Number of support vectors depends on how much slack is allowed that is (C). If C is large then we have large number of support vectors and visa -versa.\n",
        "* The support vector can lie within the margin buch still can be on the correct side.\n",
        "* the support vector can be on the worng side of the hyperplane.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Benefit of solving the dual problem instead of the primal problem.\n",
        "*  Finding an initial feasible solution to the dual is much easier than finding one for primal.  consider an example if the primal is a minimization problem then the constraints are often of the form $Ax >= b, x >=0 $ for  $b>=0$. Whereas for dual contraints would then likely be of the form  $A^{T}y<=c, y>=0,$ for $ c>=0.$ The origin is feasible for the second case but not the former.\n",
        "* Dual problem can be helpful for sensitivity analysis. when new contraints are added to the primal then the original primal soultion is infeasible. Whereas, dual adds these new contraints and its solution is still feasible.\n",
        "* Dual is much easier to solve than primal.Duality provides a lot of computational advantages over primal as lesser number of variables and a multitude of constraints.\n",
        "\n",
        "\n",
        "#Reference:\n",
        "*http://www.nathanielhobbs.com/documents/cvx_opt/cvx_opt_final_report.pdf\n",
        "\n",
        "*Class slides\n",
        "\n",
        "*https://books.google.com/books?id=tZFeAQAAQBAJ&pg=PA12&lpg=PA12&dq=lagrange%27s+for+1+norm+soft+margin&source=bl&ots=G0_8eAcscs&sig=ACfU3U0g8-eEqcL49ZmKH6bFG9RvTNTHsg&hl=en&sa=X&ved=2ahUKEwi31Ob95pPoAhUiT98KHUQSCkUQ6AEwEHoECAkQAQ#v=onepage&q=lagrange's%20for%201%20norm%20soft%20margin&f=false\n",
        "\n",
        "*https://math.stackexchange.com/questions/243706/what-are-the-advantages-of-dual-of-a-problem\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjxayMtWMH8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}